import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
from collections import Counter
import warnings

warnings.filterwarnings("ignore")

# --- 1. é…ç½®å‚æ•° ---
INPUT_FILE_NAME = "00700(1).txt"
TRAIN_END_DATE = '2023-12-31'
CLASSIFICATION_THRESHOLD = 0.005  # æ¶¨è·Œé˜ˆå€¼ delta = 0.5%

COLUMN_MAPPING = {
    'æ—¥æœŸ': 'Date', 'å¼€ç›˜': 'Open', 'æœ€é«˜': 'High', 'æœ€ä½Ž': 'Low', 
    'æ”¶ç›˜': 'Close', 'æˆäº¤é‡': 'Volume', 'æˆäº¤é¢': 'Amount'
}
encodings_to_try = ['gbk', 'gb18030', 'utf-8'] 

# --- 2. æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹å‡½æ•° (ä¸Žä¹‹å‰ä¸€è‡´ï¼Œå…ˆè®¡ç®—æ‰€æœ‰ç‰¹å¾) ---

def load_and_preprocess_raw_data(file_name):
    """è¯»å–åŽŸå§‹ TXT æ–‡ä»¶å¹¶è½¬æ¢ä¸º DataFrameã€‚"""
    # [æ­¤å¤„çœç•¥ä¸Žä¹‹å‰ä»£ç ç›¸åŒçš„ load_and_preprocess_raw_data å‡½æ•°]
    # è¯·ç¡®ä¿æ‚¨å·²ç»å°†ä¹‹å‰å®Œæ•´çš„ load_and_preprocess_raw_data æ”¾å…¥æ­¤æ–‡ä»¶ä¸­
    df = None
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_name, sep='\t', header=0, skiprows=[0], encoding=encoding)
            break
        except Exception:
            continue
    if df is None:
        raise FileNotFoundError(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æˆ–æ— æ³•è§£æžæ–‡ä»¶ '{file_name}'ã€‚")
        
    original_cols = {col: col.strip() for col in df.columns}
    df.rename(columns=original_cols, inplace=True)
    df.rename(columns=COLUMN_MAPPING, inplace=True)
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    price_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Amount']
    df[price_cols] = df[price_cols].apply(pd.to_numeric, errors='coerce')
    df.dropna(how='all', inplace=True)
    return df.copy()

def feature_engineering_all(df):
    """è®¡ç®—æ‰€æœ‰ç‰¹å¾æŒ‡æ ‡ (X) å’Œæž„å»ºæ ‡ç­¾ (Y)ã€‚"""
    # [æ­¤å¤„çœç•¥ä¸Žä¹‹å‰ä»£ç ç›¸åŒçš„å®Œæ•´çš„ feature_engineering å‡½æ•° (åŒ…å«æ‰€æœ‰33ä¸ªç‰¹å¾)]
    # æ­¤å¤„çœç•¥çš„ä»£ç åº”è¯¥åŒ…å«æ‰€æœ‰ç‰¹å¾çš„è®¡ç®—é€»è¾‘ã€‚
    # ä¸ºäº†ä¿è¯ä»£ç å¯è¿è¡Œï¼Œæˆ‘å°†æ”¾å…¥å¿…è¦çš„ä»£ç å—ï¼Œè¯·ç¡®ä¿ä¸Žæ‚¨æœ¬åœ°ç‰ˆæœ¬å¯¹é½ã€‚
    
    df.fillna(method='ffill', inplace=True)
    df = df[df['Volume'] > 0].copy()
    df['Next_Day_Close'] = df['Close'].shift(-1)
    df['Next_Day_Return'] = (df['Next_Day_Close'] / df['Close']) - 1
    df['Target'] = 0  
    df.loc[df['Next_Day_Return'] > CLASSIFICATION_THRESHOLD, 'Target'] = 1
    df.loc[df['Next_Day_Return'] < -CLASSIFICATION_THRESHOLD, 'Target'] = -1
    df['Daily_Return'] = df['Close'].pct_change() 
    
    # --- åŠ¨é‡/è¶‹åŠ¿å› å­ ---
    SHORT_WINDOW, LONG_WINDOW, SIGNAL_WINDOW = 12, 26, 9
    df['EMA_12'] = df['Close'].ewm(span=SHORT_WINDOW, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=LONG_WINDOW, adjust=False).mean()
    df['MACD_DIF'] = df['EMA_12'] - df['EMA_26']
    df['MACD_DEA'] = df['MACD_DIF'].ewm(span=SIGNAL_WINDOW, adjust=False).mean()
    df['MACD_HIST'] = df['MACD_DIF'] - df['MACD_DEA']

    # --- RSI ---
    RSI_WINDOW = 14
    delta = df['Close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    RS = gain.ewm(com=RSI_WINDOW - 1, min_periods=RSI_WINDOW).mean() / loss.ewm(com=RSI_WINDOW - 1, min_periods=RSI_WINDOW).mean()
    df['RSI'] = 100 - (100 / (1 + RS))
    
    # --- æ³¢åŠ¨çŽ‡/é‡ä»·/å½¢æ€å› å­ (éœ€è¦ Top 5 å› å­æ¶‰åŠçš„ Body_Ratio ä¾èµ–é¡¹) ---
    df['True_Range'] = df['High'] - df['Low']
    df['Body_Length'] = abs(df['Close'] - df['Open'])
    df['Body_Ratio'] = (df['Body_Length'] / df['True_Range']).replace(np.inf, 1).fillna(0) 
    
    LAG_N = 5
    for i in range(1, LAG_N + 1):
        df[f'Return_Lag_{i}'] = df['Daily_Return'].shift(i)
    
    # æ·»åŠ å…¶ä»–å¿…è¦çš„è¾…åŠ©ç‰¹å¾ï¼Œä»¥åŒ¹é…æ‚¨ä¹‹å‰33ä¸ªç‰¹å¾çš„é›†åˆï¼Œè¿™é‡Œåªæ·»åŠ äº†æœ€æ ¸å¿ƒçš„
    df['Volume_SMA_5'] = df['Volume'].rolling(window=5).mean()
    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA_5']
    df['Return_Skew'] = df['Daily_Return'].rolling(window=30).skew()
    df['Return_Kurt'] = df['Daily_Return'].rolling(window=30).kurt()
    
    # ç¡®ä¿åªä¿ç•™æ‰€éœ€çš„ç‰¹å¾å’Œæ ‡ç­¾
    df.dropna(inplace=True)
    return df

# --- 3. å› å­è¯„åˆ¤å‡½æ•° (æ ¸å¿ƒï¼šä»…ä½¿ç”¨è®­ç»ƒé›†æ•°æ®) ---

def evaluate_features_with_lgbm(df_full_features):
    """
    ä½¿ç”¨ LightGBM ä»…åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶æå–ç‰¹å¾é‡è¦æ€§æ¥è¯„åˆ¤å› å­ã€‚
    """
    # 1. ä¸¥æ ¼æŒ‰æ—¶é—´ç‚¹åˆ’åˆ†è®­ç»ƒé›†
    df_train = df_full_features.loc[df_full_features.index <= TRAIN_END_DATE].copy()
    
    # æŽ’é™¤ç”¨äºŽè®¡ç®—çš„ä¸­é—´åˆ—å’ŒåŽŸå§‹ä»·æ ¼åˆ—
    EXCLUDED_COLS = ['Next_Day_Close', 'Next_Day_Return', 'Target', 'Open', 'High', 'Low', 'Close', 'Volume', 'Amount', 
                     'True_Range', 'Body_Length', 'Volume_SMA_5'] # æŽ’é™¤è¾…åŠ©åˆ—

    FEATURE_COLUMNS = [col for col in df_train.columns if col not in EXCLUDED_COLS]
    
    X_train = df_train[FEATURE_COLUMNS]
    Y_train = df_train['Target']
    
    print("-" * 50)
    print("ðŸ“¢ å¼€å§‹è¿›è¡Œå› å­é‡è¦æ€§è¯„åˆ¤ (ä¸¥æ ¼ä»…åŸºäºŽè®­ç»ƒé›† 2018-2023)...")
    print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)} æ ·æœ¬ã€‚")
    print(f"å‚ä¸Žè¯„åˆ¤çš„ç‰¹å¾æ•°é‡: {len(FEATURE_COLUMNS)} ä¸ªã€‚")
    
    # 2. ç‰¹å¾æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # 3. è®­ç»ƒ LightGBM æ¨¡åž‹
    lgb_params = {
        'objective': 'multiclass', 'num_class': 3, 'boosting_type': 'gbdt',
        'n_estimators': 1000, 'learning_rate': 0.05, 'verbose': -1, 'n_jobs': -1, 'seed': 42
    }
    
    model = lgb.LGBMClassifier(**lgb_params)
    model.fit(X_train_scaled, Y_train)
    
    # 4. æž„å»ºé‡è¦æ€§ DataFrame
    importance_df = pd.DataFrame({
        'Feature': FEATURE_COLUMNS,
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    print("-" * 50)
    print("âœ… å› å­é‡è¦æ€§è¯„ä¼°ç»“æžœ (Top 15 - ä¸¥æ ¼æ— æ³„éœ²):")
    print(importance_df.head(15).to_markdown(index=False))
    print("-" * 50)
    
    return importance_df


# --- 4. ä¸»ç¨‹åºè¿è¡Œ ---

if __name__ == "__main__":
    
    try:
        df_full = load_and_preprocess_raw_data(INPUT_FILE_NAME)
        df_with_features = feature_engineering_all(df_full.copy())
        evaluate_features_with_lgbm(df_with_features)
        
    except FileNotFoundError as e:
        print(e)
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")