import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from collections import Counter
import warnings

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# --- 1. é…ç½®å‚æ•°å’Œæ–‡ä»¶è·¯å¾„ ---
# å‡è®¾è„šæœ¬ä¸CSVæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œæˆ–è€…ä½¿ç”¨ç»å¯¹è·¯å¾„
TRAIN_FILE_NAME = "00700_train_data_final.csv"
PREDICTING_FILE_NAME = "00700_predicting_data_final.csv"

# æœ€ç»ˆé€‰æ‹©çš„ Top 5 å› å­
FINAL_FEATURE_SET = [
    'Return_Lag_1', 'Return_Lag_5', 'Return_Lag_2', 
    'Daily_Return', 'Body_Ratio'
]
TARGET_COLUMN = 'Target'

# --- 2. æ•°æ®åŠ è½½å’Œé¢„å¤„ç† ---

def load_and_prepare_data():
    """ä»CSVæ–‡ä»¶åŠ è½½è®­ç»ƒé›†å’Œé¢„æµ‹é›†ï¼Œå¹¶è¿›è¡Œæ ‡ç­¾è½¬æ¢ã€‚"""
    try:
        # åŠ è½½è®­ç»ƒé›†
        df_train = pd.read_csv(TRAIN_FILE_NAME, index_col='Date', parse_dates=True)
        # åŠ è½½é¢„æµ‹é›† (æ³¨æ„ï¼šé¢„æµ‹é›†ä¸å‚ä¸è®­ç»ƒï¼Œåªç”¨äºé¢„æµ‹)
        df_predicting = pd.read_csv(PREDICTING_FILE_NAME, index_col='Date', parse_dates=True)
        
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ã€‚è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äºå½“å‰è¿è¡Œç›®å½•ä¸‹ï¼š{e.filename}")
        return None, None, None

    # åˆ†å‰²ç‰¹å¾ X å’Œæ ‡ç­¾ Y
    X_train = df_train[FINAL_FEATURE_SET]
    Y_train = df_train[TARGET_COLUMN]
    X_predicting = df_predicting[FINAL_FEATURE_SET]
    
    # æ ‡ç­¾è½¬æ¢ï¼šå°† {-1, 0, 1} æ˜ å°„åˆ° XGBoost æœŸæœ›çš„ {0, 1, 2}
    # -1 (è·Œ) -> 0
    # 0 (å¹³) -> 1
    # 1 (æ¶¨) -> 2
    Y_train_mapped = Y_train.replace({-1: 0, 0: 1, 1: 2})
    
    print("-" * 50)
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
    print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)} æ ·æœ¬ã€‚")
    print(f"é¢„æµ‹é›†å¤§å°: {len(X_predicting)} æ ·æœ¬ã€‚")
    print("-" * 50)
    
    return X_train, Y_train_mapped, X_predicting, Y_train

# --- 3. XGBoost æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° ---

def train_and_evaluate_xgboost(X_train, Y_train_mapped, X_predicting, Y_train_original):
    
    # 1. ç‰¹å¾æ ‡å‡†åŒ–ï¼šä»…åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆ (fit) StandardScaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    # ä½¿ç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡é‡æ¥è½¬æ¢ (transform) é¢„æµ‹é›†
    X_predicting_scaled = scaler.transform(X_predicting)
    
    # 2. åˆå§‹åŒ– XGBoost åˆ†ç±»å™¨
    # num_class=3: å¯¹åº”æ ‡ç­¾ 0, 1, 2
    xgb_model = xgb.XGBClassifier(
        objective='multi:softmax',
        num_class=3,
        n_estimators=500,
        learning_rate=0.05,
        max_depth=5,
        use_label_encoder=False,
        eval_metric='mlogloss',
        n_jobs=-1,
        seed=42 # ä¿è¯ç»“æœå¯å¤ç°
    )

    print("ğŸ“¢ å¼€å§‹è®­ç»ƒ XGBoost æ¨¡å‹ (ä»…ä½¿ç”¨è®­ç»ƒé›†æ•°æ®)...")
    
    # 3. æ¨¡å‹è®­ç»ƒ
    xgb_model.fit(X_train_scaled, Y_train_mapped)
    
    # 4. è®­ç»ƒé›†å‡†ç¡®ç‡è¯„ä¼°
    Y_train_pred_mapped = xgb_model.predict(X_train_scaled)
    
    # å°†è®­ç»ƒé›†é¢„æµ‹ç»“æœæ˜ å°„å›åŸå§‹æ ‡ç­¾ (-1, 0, 1)
    Y_train_pred = pd.Series(Y_train_pred_mapped).replace({0: -1, 1: 0, 2: 1})
    Y_train_pred.index = Y_train_original.index # å¯¹é½ç´¢å¼•
    
    train_accuracy = accuracy_score(Y_train_original, Y_train_pred)
    train_f1_macro = f1_score(Y_train_original, Y_train_pred, average='macro')
    
    print("-" * 50)
    print("ğŸ“ˆ XGBoost è®­ç»ƒé›†æ€§èƒ½è¯„ä¼°ç»“æœ:")
    print(f"ä½¿ç”¨çš„ç‰¹å¾: {FINAL_FEATURE_SET}")
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡ (Accuracy): {train_accuracy:.4f}")
    print(f"è®­ç»ƒé›† F1-Macro Score: {train_f1_macro:.4f}")
    print("-" * 50)
    print("ğŸ“‹ è®­ç»ƒé›†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(Y_train_original, Y_train_pred))
    print("-" * 50)
    
    # 5. å¯¹é¢„æµ‹é›†è¿›è¡Œé¢„æµ‹ (Prediction)
    Y_predicting_pred_mapped = xgb_model.predict(X_predicting_scaled)
    
    # å°†é¢„æµ‹ç»“æœæ˜ å°„å›åŸå§‹æ ‡ç­¾ (-1, 0, 1)
    Y_predicting_pred = pd.Series(Y_predicting_pred_mapped).replace({0: -1, 1: 0, 2: 1})
    Y_predicting_pred.index = X_predicting.index # å¯¹é½ç´¢å¼•
    Y_predicting_pred.name = 'Predicted_Target'
    
    print("âœ… æŠ•èµ„é›† (2024-01-01 åˆ° 2025-04-24) é¢„æµ‹å®Œæˆã€‚")
    print(f"é¢„æµ‹ç»“æœåˆ†å¸ƒ: {Counter(Y_predicting_pred)}")
    
    return Y_predicting_pred

# --- 4. ä¸»ç¨‹åºè¿è¡Œ ---

if __name__ == "__main__":
    
    # 1. åŠ è½½å’Œå‡†å¤‡æ•°æ®
    X_train, Y_train_mapped, X_predicting, Y_train_original = load_and_prepare_data()
    
    if X_train is not None:
        # 2. è®­ç»ƒå¹¶é¢„æµ‹
        predicted_targets = train_and_evaluate_xgboost(
            X_train, Y_train_mapped, X_predicting, Y_train_original
        )
        
        # 3. ç»“æœä¿å­˜ (å¯é€‰ï¼šå°†é¢„æµ‹ç»“æœä¿å­˜ä»¥ä¾¿åç»­å›æµ‹)
        predicted_targets.to_csv("predicted_targets_2024_2025.csv", header=True)
        print("\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ 'predicted_targets_2024_2025.csv' æ–‡ä»¶ã€‚")
        print("ğŸ‰ ä¸‹ä¸€æ­¥ï¼šä½¿ç”¨é¢„æµ‹ç»“æœè¿›è¡Œäº¤æ˜“ç­–ç•¥å›æµ‹ã€‚")