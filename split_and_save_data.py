import pandas as pd
import numpy as np
import warnings
from collections import Counter

# å¿½ç•¥ pandas çš„ SettingWithCopyWarning
warnings.filterwarnings("ignore")

# --- 1. é…ç½®å‚æ•° (ä¸¥æ ¼éµå®ˆé¡¹ç›®è¦æ±‚) ---
INPUT_FILE_NAME = "00700(1).txt"
CLASSIFICATION_THRESHOLD = 0.005  # æ¶¨è·Œé˜ˆå€¼ delta = 0.5% 

# é¡¹ç›®å®šä¹‰çš„å…³é”®æ—¥æœŸ
TRAIN_END_DATE = '2023-12-31'
INVEST_START_DATE = '2024-01-01'
INVEST_END_DATE = '2025-04-24' # æŠ•èµ„æˆªæ­¢æ—¥æœŸ

# æœ€ç»ˆé€‰æ‹©çš„ Top 5 å› å­ (åŸºäºŽLightGBMè¯„ä¼°ç»“æžœ)
FINAL_FEATURE_SET = [
    'Return_Lag_1', 'Return_Lag_5', 'Return_Lag_2', 
    'Daily_Return', 'Body_Ratio'
]
FINAL_COLUMNS = FINAL_FEATURE_SET + ['Target'] 

# è¾“å‡ºæ–‡ä»¶å
TRAIN_FILE_NAME = "00700_train_data_final.csv"
PREDICTING_FILE_NAME = "00700_predicting_data_final.csv"

# ä¸­æ–‡åˆ°è‹±æ–‡çš„åˆ—åæ˜ å°„å­—å…¸
COLUMN_MAPPING = {
    'æ—¥æœŸ': 'Date', 'å¼€ç›˜': 'Open', 'æœ€é«˜': 'High', 'æœ€ä½Ž': 'Low', 
    'æ”¶ç›˜': 'Close', 'æˆäº¤é‡': 'Volume', 'æˆäº¤é¢': 'Amount'
}
encodings_to_try = ['gbk', 'gb18030', 'utf-8'] 

# --- 2. æ–‡ä»¶è¯»å–å’Œæ ¼å¼è½¬æ¢ ---

def load_and_preprocess_raw_data(file_name):
    """è¯»å–åŽŸå§‹ TXT æ–‡ä»¶å¹¶è½¬æ¢ä¸º DataFrameã€‚"""
    df = None
    print(f"å°è¯•è¯»å–æ–‡ä»¶ï¼š{file_name}")
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_name, sep='\t', header=0, skiprows=[0], encoding=encoding)
            print(f"  - æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–ã€‚")
            break
        except Exception:
            continue

    if df is None:
        print("âŒ è¯»å–å¤±è´¥ï¼šæ‰€æœ‰å°è¯•çš„ç¼–ç éƒ½æ— æ³•æ­£ç¡®è§£æžæ–‡ä»¶ã€‚")
        return None

    # æ¸…ç†å’Œé‡å‘½å
    original_cols = {col: col.strip() for col in df.columns}
    df.rename(columns=original_cols, inplace=True)
    df.rename(columns=COLUMN_MAPPING, inplace=True)
    
    # ç±»åž‹è½¬æ¢
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    price_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Amount']
    df[price_cols] = df[price_cols].apply(pd.to_numeric, errors='coerce')
    df.dropna(how='all', inplace=True)
    
    return df.copy()

# --- 3. å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹å‡½æ•° ---

def feature_engineering(df):
    """è®¡ç®—æ‰€æœ‰ Top 5 å› å­æ‰€éœ€çš„ç‰¹å¾ï¼Œä»¥åŠ Target æ ‡ç­¾ã€‚"""
    
    # åŸºç¡€æ¸…æ´—ä¸Žæ ‡ç­¾æž„å»º (Y)
    df.fillna(method='ffill', inplace=True)
    df = df[df['Volume'] > 0].copy()
    
    # 1. ç›®æ ‡æ ‡ç­¾ Target (Y)
    df['Next_Day_Close'] = df['Close'].shift(-1)
    df['Next_Day_Return'] = (df['Next_Day_Close'] / df['Close']) - 1
    df['Target'] = 0  
    df.loc[df['Next_Day_Return'] > CLASSIFICATION_THRESHOLD, 'Target'] = 1
    df.loc[df['Next_Day_Return'] < -CLASSIFICATION_THRESHOLD, 'Target'] = -1
    
    # 2. Daily_Return (R_t) å’Œæ»žåŽç‰¹å¾
    df['Daily_Return'] = df['Close'].pct_change() 
    LAG_N = 5
    for i in range(1, LAG_N + 1):
        df[f'Return_Lag_{i}'] = df['Daily_Return'].shift(i)

    # 3. Body_Ratio
    df['True_Range'] = df['High'] - df['Low']
    df['Body_Length'] = abs(df['Close'] - df['Open'])
    # Body_Ratio: é¿å…é™¤ä»¥é›¶
    df['Body_Ratio'] = (df['Body_Length'] / df['True_Range']).replace(np.inf, 1).fillna(0) 

    # æ¸…ç†æ‰€æœ‰ NaN å€¼ï¼ˆå¤§éƒ¨åˆ†ç”±æ»žåŽçª—å£å’Œ Body_Ratio å¯¼è‡´ï¼‰
    df.dropna(inplace=True)

    return df

# --- 4. ä¸»ç¨‹åºè¿è¡Œï¼šç‰¹å¾æå–ã€åˆ†å‰²å’Œä¿å­˜ ---

if __name__ == "__main__":
    
    # 1. è¯»å–å’Œè®¡ç®—æ‰€æœ‰ç‰¹å¾
    df_full = load_and_preprocess_raw_data(INPUT_FILE_NAME)
    
    if df_full is not None:
        df_with_features = feature_engineering(df_full)
        
        # 2. ç­›é€‰æœ€ç»ˆç‰¹å¾é›† (Top 5 å› å­ + Target)
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        missing_cols = [col for col in FINAL_COLUMNS if col not in df_with_features.columns]
        if missing_cols:
            print(f"âŒ é”™è¯¯ï¼šåœ¨è®¡ç®—å‡ºçš„ç‰¹å¾ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_cols}ã€‚è¯·æ£€æŸ¥ feature_engineering å‡½æ•°ã€‚")
            exit()
            
        df_final = df_with_features[FINAL_COLUMNS].copy()
        
        print("-" * 50)
        print(f"âœ… æœ€ç»ˆç‰¹å¾é›†ç­›é€‰å®Œæˆï¼æ€»æœ‰æ•ˆæ ·æœ¬æ•°: {len(df_final)}ã€‚")
        print(f"é€‰å–çš„ç‰¹å¾å’Œæ ‡ç­¾ï¼š{FINAL_COLUMNS}")

        # 3. æŒ‰æ—¶é—´ç‚¹åˆ†å‰²æ•°æ®é›† (ä¸¥æ ¼çš„éžé‡å æ—¶é—´åˆ’åˆ†)
        
        # è®­ç»ƒé›†: 2018/01/02 åˆ° 2023/12/31
        df_train = df_final.loc[df_final.index <= TRAIN_END_DATE].copy()
        
        # æŠ•èµ„é›†/é¢„æµ‹é›†: 2024/01/01 åˆ° 2025/04/24
        # ä½¿ç”¨ loc[start:end] ç¡®ä¿åªåŒ…å«æ‰€éœ€æ—¶é—´æ®µ
        df_predicting = df_final.loc[(df_final.index >= INVEST_START_DATE) & (df_final.index <= INVEST_END_DATE)].copy()

        # 4. ä¿å­˜ä¸º CSV æ–‡ä»¶
        
        # è®­ç»ƒé›†ä¿å­˜
        df_train.to_csv(TRAIN_FILE_NAME, encoding='utf-8')
        print("-" * 50)
        print(f"ðŸ’¾ è®­ç»ƒé›†æ•°æ®å·²ä¿å­˜åˆ°ï¼š'{TRAIN_FILE_NAME}'")
        print(f"   è®­ç»ƒé›†æ—¥æœŸèŒƒå›´ï¼š{df_train.index.min()} - {df_train.index.max()}")
        print(f"   è®­ç»ƒé›†å¤§å°: {len(df_train)} ä¸ªæ ·æœ¬ã€‚")
        print(f"   è®­ç»ƒé›† Target åˆ†å¸ƒ: {Counter(df_train['Target'])}")

        # é¢„æµ‹é›†ä¿å­˜
        df_predicting.to_csv(PREDICTING_FILE_NAME, encoding='utf-8')
        print("-" * 50)
        print(f"ðŸ’¾ é¢„æµ‹é›†æ•°æ®å·²ä¿å­˜åˆ°ï¼š'{PREDICTING_FILE_NAME}'")
        print(f"   é¢„æµ‹é›†æ—¥æœŸèŒƒå›´ï¼š{df_predicting.index.min()} - {df_predicting.index.max()}")
        print(f"   é¢„æµ‹é›†å¤§å°: {len(df_predicting)} ä¸ªæ ·æœ¬ã€‚")
        print("-" * 50)
        
        print("\nðŸŽ‰ ä¸‹ä¸€æ­¥ï¼šä½¿ç”¨è¿™ä¸¤ä¸ªæ–‡ä»¶è¿›è¡Œ XGBoost/LightGBM æ¨¡åž‹è®­ç»ƒã€‚")