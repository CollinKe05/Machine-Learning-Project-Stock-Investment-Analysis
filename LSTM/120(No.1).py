import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import random
import os
import json
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping
import tensorflow as tf

plt.rcParams['font.sans-serif'] = ['SimSun']
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False


# ================= 1. è®¾ç½®å…¨å±€éšæœºç§å­ =================
def set_random_seeds(seed=38):
    """è®¾ç½®æ‰€æœ‰ç›¸å…³éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    # Pythonå’Œç³»ç»Ÿç¯å¢ƒ
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

    # Pythonéšæœºæ¨¡å—
    random.seed(seed)
    np.random.seed(seed)

    # TensorFlow/Keras
    tf.random.set_seed(seed)
    tf.keras.utils.set_random_seed(seed)

    # å°è¯•å¯ç”¨ç¡®å®šæ€§æ“ä½œ
    try:
        tf.config.experimental.enable_op_determinism()
    except:
        pass  # æ—§ç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒ

    # é…ç½®GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print(f"GPUé…ç½®é”™è¯¯: {e}")


# ================= æ–°å¢ï¼šæ¨¡å‹è¯„åˆ†å‡½æ•° =================
def calculate_model_score(r2_val, rmse_val, dir_accuracy, weights=(0.3, 0.3, 0.4)):
    """
    è®¡ç®—æ¨¡å‹ç»¼åˆå¾—åˆ†

    å‚æ•°:
    - r2_val: R2åˆ†æ•°ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    - rmse_val: RMSEï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    - dir_accuracy: æ–¹å‘å‡†ç¡®ç‡ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    - weights: (r2æƒé‡, rmseæƒé‡, æ–¹å‘å‡†ç¡®ç‡æƒé‡)

    è¿”å›:
    - score: ç»¼åˆå¾—åˆ†ï¼ˆ0-100ï¼‰
    """
    # å½’ä¸€åŒ–å¤„ç†
    # R2: ç†è®ºä¸ŠèŒƒå›´ä¸º[-âˆ, 1]ï¼Œä½†å®è·µä¸­é€šå¸¸>0ï¼Œæˆ‘ä»¬é™åˆ¶åˆ°[0,1]
    norm_r2 = max(0, min(1, r2_val))

    # RMSE: éœ€è¦è½¬æ¢ä¸ºå¾—åˆ†ï¼ŒRMSEè¶Šå°è¶Šå¥½
    # è¿™é‡Œä½¿ç”¨ç›¸å¯¹å¾—åˆ†ï¼Œå‡è®¾RMSEåœ¨åˆç†èŒƒå›´å†…
    # ä½¿ç”¨æŒ‡æ•°è¡°å‡å‡½æ•°å°†RMSEè½¬æ¢ä¸ºå¾—åˆ†
    rmse_score = 100 * math.exp(-rmse_val / 100) if rmse_val > 0 else 100

    # æ–¹å‘å‡†ç¡®ç‡ï¼šå·²ç»æ˜¯ç™¾åˆ†æ¯”ï¼Œå½’ä¸€åŒ–åˆ°0-1
    norm_dir_acc = dir_accuracy / 100

    # è®¡ç®—åŠ æƒå¾—åˆ†
    score = (norm_r2 * weights[0] + rmse_score / 100 * weights[1] + norm_dir_acc * weights[2]) * 100

    return score


# ================= 2. æ•°æ®åˆ’åˆ†å‚æ•° =================
FILE_PATH = '00700_cleaned.csv'
PRE_TRAIN_END = '2023-06-30'  # é¢„è®­ç»ƒé›†ç»“æŸ
VALID_START = '2023-07-01'  # éªŒè¯é›†å¼€å§‹
VALID_END = '2023-12-31'  # éªŒè¯é›†ç»“æŸ
TEST_START = '2024-01-01'  # æµ‹è¯•é›†å¼€å§‹
LOOKBACK = 15
EPOCHS = 60
BATCH_SIZE = 16
COMMISSION = 0
SEED = 38  # å›ºå®šéšæœºç§å­


# ================= 3. æ•°æ®åŠ è½½ä¸åˆ’åˆ†å‡½æ•° =================
def calculate_macd(df, fast=12, slow=26, signal=9):
    exp1 = df['Close'].ewm(span=fast, adjust=False).mean()
    exp2 = df['Close'].ewm(span=slow, adjust=False).mean()
    df['DIF'] = exp1 - exp2
    df['DEA'] = df['DIF'].ewm(span=signal, adjust=False).mean()
    df['MACD_Hist'] = (df['DIF'] - df['DEA']) * 2
    return df


def process_stock_data(file_path):
    df = pd.read_csv(file_path)
    df['Date'] = pd.to_datetime(df['Date'])
    df.sort_values('Date', inplace=True)
    df.reset_index(drop=True, inplace=True)
    df['MA5'] = df['Close'].rolling(5).mean()
    df['MA20'] = df['Close'].rolling(20).mean()
    df = calculate_macd(df)
    df['Momentum'] = df['Close'] - df['Close'].shift(5)
    df.dropna(inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df


def create_dataset(dataset_X, dataset_Y, look_back=1):
    X, Y = [], []
    for i in range(len(dataset_X) - look_back):
        X.append(dataset_X[i:(i + look_back)])
        Y.append(dataset_Y[i + look_back])
    return np.array(X), np.array(Y)


# ================= æ–°å¢ï¼šæ–¹å‘å‡†ç¡®ç‡è®¡ç®—å‡½æ•° =================
def calculate_direction_accuracy(y_true, y_pred, look_ahead=1):
    """
    è®¡ç®—æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡

    å‚æ•°:
    - y_true: çœŸå®ä»·æ ¼æ•°ç»„
    - y_pred: é¢„æµ‹ä»·æ ¼æ•°ç»„
    - look_ahead: é¢„æµ‹çš„æ—¶é—´æ­¥é•¿ï¼ˆé»˜è®¤1ï¼Œå³é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹ï¼‰

    è¿”å›:
    - accuracy: æ–¹å‘å‡†ç¡®ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    - correct_predictions: æ­£ç¡®é¢„æµ‹çš„æ•°é‡
    - total_predictions: æ€»é¢„æµ‹æ•°é‡
    - up_accuracy: ä¸Šæ¶¨é¢„æµ‹å‡†ç¡®ç‡
    - down_accuracy: ä¸‹è·Œé¢„æµ‹å‡†ç¡®ç‡
    """
    if len(y_true) != len(y_pred):
        min_len = min(len(y_true), len(y_pred))
        y_true = y_true[:min_len]
        y_pred = y_pred[:min_len]

    # è®¡ç®—çœŸå®æ–¹å‘ (1:ä¸Šæ¶¨, 0:ä¸‹è·Œ)
    true_directions = []
    for i in range(len(y_true) - look_ahead):
        if y_true[i + look_ahead] > y_true[i]:
            true_directions.append(1)  # ä¸Šæ¶¨
        else:
            true_directions.append(0)  # ä¸‹è·Œæˆ–æŒå¹³

    # è®¡ç®—é¢„æµ‹æ–¹å‘
    pred_directions = []
    for i in range(len(y_pred) - look_ahead):
        if y_pred[i + look_ahead] > y_true[i]:
            pred_directions.append(1)  # é¢„æµ‹ä¸Šæ¶¨
        else:
            pred_directions.append(0)  # é¢„æµ‹ä¸‹è·Œæˆ–æŒå¹³

    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    correct = sum(1 for t, p in zip(true_directions, pred_directions) if t == p)
    total = len(true_directions)
    accuracy = (correct / total) * 100 if total > 0 else 0

    # è®¡ç®—ä¸Šæ¶¨é¢„æµ‹å‡†ç¡®ç‡
    true_up_indices = [i for i, d in enumerate(true_directions) if d == 1]
    correct_up = sum(1 for i in true_up_indices if pred_directions[i] == 1)
    up_accuracy = (correct_up / len(true_up_indices) * 100) if true_up_indices else 0

    # è®¡ç®—ä¸‹è·Œé¢„æµ‹å‡†ç¡®ç‡
    true_down_indices = [i for i, d in enumerate(true_directions) if d == 0]
    correct_down = sum(1 for i in true_down_indices if pred_directions[i] == 0)
    down_accuracy = (correct_down / len(true_down_indices) * 100) if true_down_indices else 0

    return accuracy, correct, total, up_accuracy, down_accuracy


# ================= 4. æ”¹è¿›çš„è®­ç»ƒç­–ç•¥ =================
def train_with_validation():
    """ä½¿ç”¨éªŒè¯é›†é€‰æ‹©æœ€ä½³æ¨¡å‹"""
    # è®¾ç½®å…¨å±€éšæœºç§å­
    set_random_seeds(SEED)

    print(">>> è¯»å–å’Œå¤„ç†æ•°æ®...")
    df = process_stock_data(FILE_PATH)

    # æ•°æ®åˆ’åˆ†ï¼šä¸‰é˜¶æ®µ
    pre_train_df = df[df['Date'] <= PRE_TRAIN_END].copy()
    valid_df = df[(df['Date'] >= VALID_START) & (df['Date'] <= VALID_END)].copy()
    test_df_raw = df[df['Date'] >= TEST_START].copy()

    print(
        f"é¢„è®­ç»ƒé›†: {len(pre_train_df)} å¤© ({pre_train_df['Date'].min().date()} - {pre_train_df['Date'].max().date()})")
    print(f"éªŒè¯é›†: {len(valid_df)} å¤© ({valid_df['Date'].min().date()} - {valid_df['Date'].max().date()})")
    print(f"æµ‹è¯•é›†: {len(test_df_raw)} å¤© ({test_df_raw['Date'].min().date()} - {test_df_raw['Date'].max().date()})")

    # ç‰¹å¾åˆ—
    feature_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA5', 'MA20',
                    'DIF', 'DEA', 'MACD_Hist']
    target_col = ['Close']

    # åˆ›å»ºscalerï¼ˆä»…åœ¨é¢„è®­ç»ƒé›†ä¸Šæ‹Ÿåˆï¼‰
    scaler_X = MinMaxScaler(feature_range=(0, 1))
    scaler_Y = MinMaxScaler(feature_range=(0, 1))

    scaler_X.fit(pre_train_df[feature_cols])
    scaler_Y.fit(pre_train_df[target_col])

    # å‡†å¤‡é¢„è®­ç»ƒæ•°æ®
    pre_train_X_scaled = scaler_X.transform(pre_train_df[feature_cols])
    pre_train_Y_scaled = scaler_Y.transform(pre_train_df[target_col])
    pre_train_X, pre_train_Y = create_dataset(pre_train_X_scaled, pre_train_Y_scaled, LOOKBACK)

    # å‡†å¤‡éªŒè¯æ•°æ®
    full_valid = pd.concat((pre_train_df.iloc[-LOOKBACK:], valid_df))
    valid_X_scaled_long = scaler_X.transform(full_valid[feature_cols])
    valid_X, _ = create_dataset(valid_X_scaled_long, np.zeros(len(valid_X_scaled_long)), LOOKBACK)

    # ================= 5. è®­ç»ƒé˜¶æ®µ =================
    print("\n>>> å¼€å§‹è®­ç»ƒï¼ˆ10ä¸ªå‚æ•°ç»„åˆï¼‰...")

    # å°è¯•ä¸åŒçš„è¶…å‚æ•°
    best_model = None
    best_score = -float('inf')  # æ”¹ä¸ºä½¿ç”¨ç»¼åˆå¾—åˆ†
    best_params = {}
    best_valid_direction_accuracy = 0

    # è®°å½•æ‰€æœ‰å‚æ•°ç»„åˆç»“æœ
    results_history = []

    # ================= 10ä¸ªç²¾é€‰å‚æ•°ç»„åˆ =================
    # ç²¾å¿ƒæŒ‘é€‰çš„10ä¸ªç»„åˆï¼Œè¦†ç›–ä¸åŒé…ç½®
    parameter_combinations = [
        # (units1, units2, dropout, learning_rate, description)
        (128, 64, 0.2, 0.001, "æ ‡å‡†ä¸­å‹ç½‘ç»œ"),
        (64, 32, 0.3, 0.001, "å°å‹ä¿å®ˆç½‘ç»œ"),
        (256, 128, 0.2, 0.0005, "å¤§å‹ç½‘ç»œä½å­¦ä¹ ç‡"),
        (128, 128, 0.3, 0.001, "å¯¹ç§°ç½‘ç»œ"),
        (64, 64, 0.4, 0.001, "ç´§å‡‘é«˜Dropout"),
        (128, 64, 0.3, 0.0005, "ä¸­å‹ä¿å®ˆ"),
        (256, 256, 0.2, 0.001, "å¤§å‹å¯¹ç§°"),
        (64, 32, 0.2, 0.0005, "å°å‹ä½å­¦ä¹ ç‡"),
        (128, 128, 0.4, 0.0005, "å¯¹ç§°é«˜Dropout"),
        (256, 128, 0.3, 0.001, "å¤§å‹æ ‡å‡†"),
    ]

    total_combinations = len(parameter_combinations)

    for idx, (units1, units2, dropout_rate, lr, description) in enumerate(parameter_combinations, 1):
        print(f"\n--- å°è¯•ç»„åˆ {idx}/{total_combinations}: {description} ---")
        print(f"LSTM: ({units1}, {units2}), Dropout: {dropout_rate}, LR: {lr}")

        # æ¸…é™¤ä¹‹å‰çš„è®¡ç®—å›¾å¹¶é‡æ–°è®¾ç½®ç§å­
        tf.keras.backend.clear_session()
        set_random_seeds(SEED + idx)  # å¾®è°ƒç§å­

        # æ„å»ºæ¨¡å‹
        model = Sequential()
        model.add(LSTM(units1, return_sequences=True,
                       input_shape=(LOOKBACK, len(feature_cols))))
        model.add(Dropout(dropout_rate))
        model.add(LSTM(units2, return_sequences=False))
        model.add(Dropout(dropout_rate))
        model.add(Dense(32, activation='relu'))
        model.add(Dense(1))

        # ä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡çš„ä¼˜åŒ–å™¨
        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
        model.compile(loss='mse', optimizer=optimizer)

        # æ—©åœï¼ˆç›‘æ§è®­ç»ƒæŸå¤±ï¼‰
        early_stop = EarlyStopping(
            monitor='loss',
            patience=6,
            restore_best_weights=True
        )

        # è®­ç»ƒ
        history = model.fit(
            pre_train_X, pre_train_Y,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            verbose=0,
            callbacks=[early_stop]
        )

        # ================= 6. éªŒè¯é˜¶æ®µ =================
        print(">>> åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°...")

        # åœ¨éªŒè¯é›†ä¸Šé¢„æµ‹
        valid_predict = model.predict(valid_X, verbose=0)
        valid_predict_real = scaler_Y.inverse_transform(valid_predict)

        # åˆ›å»ºéªŒè¯ç»“æœDataFrame
        valid_len = min(len(valid_df), len(valid_predict_real))
        valid_result_df = valid_df.iloc[:valid_len].copy()
        valid_result_df['Predicted'] = valid_predict_real[:valid_len].flatten()

        # åœ¨éªŒè¯é›†ä¸Šæ‰§è¡Œç­–ç•¥
        valid_return = run_strategy_on_data(valid_result_df)

        # è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡æŒ‡æ ‡
        y_true_val = valid_result_df['Close'].values
        y_pred_val = valid_result_df['Predicted'].values
        r2_val = r2_score(y_true_val, y_pred_val)
        rmse_val = math.sqrt(mean_squared_error(y_true_val, y_pred_val))

        # æ–°å¢ï¼šè®¡ç®—éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡
        valid_dir_accuracy, valid_correct, valid_total, valid_up_acc, valid_down_acc = calculate_direction_accuracy(
            y_true_val, y_pred_val, look_ahead=1
        )

        # è®¡ç®—æ¨¡å‹ç»¼åˆå¾—åˆ†ï¼ˆä½¿ç”¨R2ã€RMSEå’Œæ–¹å‘å‡†ç¡®ç‡ï¼‰
        model_score = calculate_model_score(
            r2_val,
            rmse_val,
            valid_dir_accuracy,
            weights=(0.3, 0.3, 0.4)  # R2æƒé‡30%ï¼ŒRMSEæƒé‡30%ï¼Œæ–¹å‘å‡†ç¡®ç‡æƒé‡40%
        )

        print(f"éªŒè¯é›†R2: {r2_val:.4f}, RMSE: {rmse_val:.2f}")
        print(f"éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {valid_dir_accuracy:.2f}% ({valid_correct}/{valid_total})")
        print(f"éªŒè¯é›†ä¸Šæ¶¨å‡†ç¡®ç‡: {valid_up_acc:.2f}%, ä¸‹è·Œå‡†ç¡®ç‡: {valid_down_acc:.2f}%")
        print(f"éªŒè¯é›†æ”¶ç›Šç‡: {valid_return * 100:.2f}%")
        print(f"æ¨¡å‹ç»¼åˆå¾—åˆ†: {model_score:.2f}")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        full_test = pd.concat((df[df['Date'] <= VALID_END].iloc[-LOOKBACK:], test_df_raw))
        test_X_scaled_long = scaler_X.transform(full_test[feature_cols])
        test_X, _ = create_dataset(test_X_scaled_long, np.zeros(len(test_X_scaled_long)), LOOKBACK)

        # é¢„æµ‹
        test_predict = model.predict(test_X, verbose=0)
        test_predict_real = scaler_Y.inverse_transform(test_predict)

        # åˆ›å»ºæµ‹è¯•ç»“æœ
        test_len = min(len(test_df_raw), len(test_predict_real))
        result_df = test_df_raw.iloc[:test_len].copy()
        result_df['Predicted'] = test_predict_real[:test_len].flatten()

        # è®¡ç®—æµ‹è¯•é›†æ”¶ç›Šç‡
        test_return = run_strategy_on_data(result_df)

        # è¯„ä¼°æŒ‡æ ‡
        y_true = result_df['Close'].values
        y_pred = result_df['Predicted'].values
        r2 = r2_score(y_true, y_pred)
        rmse = math.sqrt(mean_squared_error(y_true, y_pred))

        # æ–°å¢ï¼šè®¡ç®—æµ‹è¯•é›†æ–¹å‘å‡†ç¡®ç‡
        test_dir_accuracy, test_correct, test_total, test_up_acc, test_down_acc = calculate_direction_accuracy(
            y_true, y_pred, look_ahead=1
        )

        print(f"\n{'=' * 60}")
        print(f"ç»„åˆ {idx} æµ‹è¯•ç»“æœ:")
        print(f"R2 Score: {r2:.4f}")
        print(f"RMSE: {rmse:.2f}")
        print(f"æµ‹è¯•é›†æ”¶ç›Šç‡: {test_return * 100:.2f}%")
        print(f"æµ‹è¯•é›†æ–¹å‘å‡†ç¡®ç‡: {test_dir_accuracy:.2f}% ({test_correct}/{test_total})")
        print(f"æµ‹è¯•é›†ä¸Šæ¶¨å‡†ç¡®ç‡: {test_up_acc:.2f}%, ä¸‹è·Œå‡†ç¡®ç‡: {test_down_acc:.2f}%")
        print(f"éªŒè¯é›†R2: {r2_val:.4f}, RMSE: {rmse_val:.2f}")
        print(f"éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {valid_dir_accuracy:.2f}%")
        print(f"æ¨¡å‹ç»¼åˆå¾—åˆ†: {model_score:.2f}")
        print(f"{'=' * 60}")

        # è®¡ç®—å›æ’¤
        asset_series = pd.Series(result_df['Asset'].values)
        cumulative_max = asset_series.cummax()
        drawdown = (asset_series - cumulative_max) / cumulative_max * 100
        max_dd = drawdown.min()
        print(f'å›æ’¤åˆ†æ | æœ€å¤§å›æ’¤: {max_dd:.1f}%')

        # ä¿å­˜ç»“æœå†å²ï¼ˆæ–°å¢æ¨¡å‹å¾—åˆ†å­—æ®µï¼‰
        result_info = {
            'ç»„åˆ': idx,
            'æè¿°': description,
            'units1': units1,
            'units2': units2,
            'dropout': dropout_rate,
            'learning_rate': lr,
            'valid_return': valid_return,
            'valid_r2': r2_val,
            'valid_rmse': rmse_val,
            'valid_direction_accuracy': valid_dir_accuracy,
            'valid_up_accuracy': valid_up_acc,
            'valid_down_accuracy': valid_down_acc,
            'model_score': model_score,
            'test_return': test_return,
            'test_r2': r2,
            'test_rmse': rmse,
            'test_direction_accuracy': test_dir_accuracy,
            'test_up_accuracy': test_up_acc,
            'test_down_accuracy': test_down_acc,
            'max_drawdown': max_dd,
            'epochs_trained': len(history.history['loss'])
        }
        results_history.append(result_info)

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºæ¨¡å‹ç»¼åˆå¾—åˆ†ï¼‰
        if model_score > best_score:
            best_score = model_score
            best_valid_direction_accuracy = valid_dir_accuracy
            best_model = model
            best_params = {
                'ç»„åˆ': idx,
                'æè¿°': description,
                'units': (units1, units2),
                'dropout': dropout_rate,
                'learning_rate': lr,
                'valid_return': valid_return,
                'valid_r2': r2_val,
                'valid_rmse': rmse_val,
                'valid_direction_accuracy': valid_dir_accuracy,
                'model_score': model_score,
                'test_return': test_return,
                'test_r2': r2,
                'test_rmse': rmse,
                'test_direction_accuracy': test_dir_accuracy,
                'r2_score': r2_val,
                'rmse': rmse_val
            }
            print(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹ï¼æ¨¡å‹ç»¼åˆå¾—åˆ†: {model_score:.2f}, æ–¹å‘å‡†ç¡®ç‡: {valid_dir_accuracy:.2f}%")

    # ================= 7. ç»“æœåˆ†æ =================
    print(f"\n{'=' * 60}")
    print("å‚æ•°æœç´¢å®Œæˆï¼ç»“æœåˆ†æ:")
    print(f"{'=' * 60}")

    # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
    results_df = pd.DataFrame(results_history)
    results_df = results_df.sort_values('model_score', ascending=False)

    print("\nğŸ“Š æ‰€æœ‰å‚æ•°ç»„åˆç»“æœï¼ˆæŒ‰æ¨¡å‹ç»¼åˆå¾—åˆ†æ’åºï¼‰:")
    print(results_df[['ç»„åˆ', 'æè¿°', 'model_score', 'valid_direction_accuracy',
                      'valid_r2', 'valid_rmse', 'valid_return',
                      'test_direction_accuracy', 'test_return']].to_string())

    print(f"\n{'=' * 60}")
    print("ğŸ¯ æœ€ä½³æ¨¡å‹å‚æ•°ï¼ˆåŸºäºç»¼åˆå¾—åˆ†ï¼‰:")
    print(f"ç»„åˆ: {best_params['ç»„åˆ']} - {best_params['æè¿°']}")
    print(f"LSTM Units: {best_params['units']}")
    print(f"Dropout Rate: {best_params['dropout']}")
    print(f"Learning Rate: {best_params['learning_rate']}")
    print(f"æ¨¡å‹ç»¼åˆå¾—åˆ†: {best_params['model_score']:.2f}")
    print(f"éªŒè¯é›†R2: {best_params['valid_r2']:.4f}")
    print(f"éªŒè¯é›†RMSE: {best_params['valid_rmse']:.2f}")
    print(f"éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {best_params['valid_direction_accuracy']:.2f}%")
    print(f"éªŒè¯é›†æ”¶ç›Šç‡: {best_params['valid_return'] * 100:.2f}%")
    print(f"æµ‹è¯•é›†R2: {best_params['test_r2']:.4f}")
    print(f"æµ‹è¯•é›†RMSE: {best_params['test_rmse']:.2f}")
    print(f"æµ‹è¯•é›†æ–¹å‘å‡†ç¡®ç‡: {best_params['test_direction_accuracy']:.2f}%")
    print(f"æµ‹è¯•é›†æ”¶ç›Šç‡: {best_params['test_return'] * 100:.2f}%")
    print(f"{'=' * 60}")

    # æŒ‰æ–¹å‘å‡†ç¡®ç‡æ’åº
    print("\nğŸ“Š æ‰€æœ‰å‚æ•°ç»„åˆç»“æœï¼ˆæŒ‰éªŒè¯æ–¹å‘å‡†ç¡®ç‡æ’åºï¼‰:")
    dir_acc_sorted = results_df.sort_values('valid_direction_accuracy', ascending=False)
    print(dir_acc_sorted[['ç»„åˆ', 'æè¿°', 'valid_direction_accuracy', 'model_score', 'valid_return',
                          'test_direction_accuracy', 'test_return']].to_string())

    # ä¿å­˜ç»“æœå†å²
    results_df.to_csv('top10_parameter_results.csv', index=False, encoding='utf-8')
    print("âœ… å‚æ•°æœç´¢ç»“æœå·²ä¿å­˜åˆ° top10_parameter_results.csv")

    # ================= 8. æµ‹è¯•é˜¶æ®µï¼ˆæœ€ç»ˆè¯„ä¼°ï¼‰ =================
    print("\n>>> åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹...")

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    full_test = pd.concat((df[df['Date'] <= VALID_END].iloc[-LOOKBACK:], test_df_raw))
    test_X_scaled_long = scaler_X.transform(full_test[feature_cols])
    test_X, _ = create_dataset(test_X_scaled_long, np.zeros(len(test_X_scaled_long)), LOOKBACK)

    # é¢„æµ‹
    test_predict = best_model.predict(test_X, verbose=0)
    test_predict_real = scaler_Y.inverse_transform(test_predict)

    # åˆ›å»ºæµ‹è¯•ç»“æœ
    test_len = min(len(test_df_raw), len(test_predict_real))
    result_df = test_df_raw.iloc[:test_len].copy()
    result_df['Predicted'] = test_predict_real[:test_len].flatten()

    # è®¡ç®—æµ‹è¯•é›†æ”¶ç›Šç‡
    test_return = run_strategy_on_data(result_df)

    # è¯„ä¼°æŒ‡æ ‡
    y_true = result_df['Close'].values
    y_pred = result_df['Predicted'].values
    r2 = r2_score(y_true, y_pred)
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))

    # æœ€ç»ˆçš„æ–¹å‘å‡†ç¡®ç‡è®¡ç®—
    final_dir_accuracy, final_correct, final_total, final_up_acc, final_down_acc = calculate_direction_accuracy(
        y_true, y_pred, look_ahead=1
    )

    # è®¡ç®—å›æ’¤
    asset_series = pd.Series(result_df['Asset'].values)
    cumulative_max = asset_series.cummax()
    drawdown = (asset_series - cumulative_max) / cumulative_max * 100
    max_dd = drawdown.min()

    print(f"\n{'=' * 60}")
    print("æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"R2 Score: {r2:.4f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"æµ‹è¯•é›†æ”¶ç›Šç‡: {test_return * 100:.2f}%")
    print(f"æµ‹è¯•é›†æ–¹å‘å‡†ç¡®ç‡: {final_dir_accuracy:.2f}% ({final_correct}/{final_total})")
    print(f"æµ‹è¯•é›†ä¸Šæ¶¨å‡†ç¡®ç‡: {final_up_acc:.2f}%, ä¸‹è·Œå‡†ç¡®ç‡: {final_down_acc:.2f}%")
    print(f"æœ€å¤§å›æ’¤: {max_dd:.1f}%")
    print(f"æ¨¡å‹ç»¼åˆå¾—åˆ†: {best_score:.2f}")
    print(f"éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {best_valid_direction_accuracy:.2f}%")
    print(f"{'=' * 60}")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if test_return > -0.1:  # å…è®¸å°å¹…è´Ÿæ”¶ç›Š
        model_filename = f'best_model_top10_combo{best_params["ç»„åˆ"]}_score{best_score:.1f}.keras'
        best_model.save(model_filename)
        print(f"\nâœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: {model_filename}")

        # ä¿å­˜å‚æ•°è®°å½•ï¼ˆæ–°å¢æ¨¡å‹å¾—åˆ†ï¼‰
        params_record = {
            'best_model_score': float(best_score),
            'best_valid_direction_accuracy': float(best_valid_direction_accuracy),
            'best_valid_r2': float(best_params['valid_r2']),
            'best_valid_rmse': float(best_params['valid_rmse']),
            'test_return': float(test_return),
            'test_direction_accuracy': float(final_dir_accuracy),
            'test_up_accuracy': float(final_up_acc),
            'test_down_accuracy': float(final_down_acc),
            'r2_score': float(r2),
            'rmse': float(rmse),
            'max_drawdown': float(max_dd),
            'best_params': best_params,
            'data_split': {
                'pre_train_end': PRE_TRAIN_END,
                'valid_start': VALID_START,
                'valid_end': VALID_END,
                'test_start': TEST_START
            },
            'random_seed': SEED,
            'feature_cols': feature_cols,
            'lookback': LOOKBACK,
            'epochs': EPOCHS,
            'batch_size': BATCH_SIZE,
            'all_results': results_history
        }

        with open('best_model_params_top10.json', 'w', encoding='utf-8') as f:
            json.dump(params_record, f, indent=2, ensure_ascii=False)

        # å¯è§†åŒ–ï¼ˆæ›´æ–°å›¾è¡¨ä»¥åŒ…å«æ¨¡å‹å¾—åˆ†ä¿¡æ¯ï¼‰
        create_final_report(result_df, r2, test_return, best_score,
                            final_dir_accuracy, best_valid_direction_accuracy, results_df)

    return best_model, result_df, test_return, results_df


# ================= 9. ç­–ç•¥æ‰§è¡Œå‡½æ•° =================
def run_strategy_on_data(result_df):
    """åœ¨ç»™å®šæ•°æ®ä¸Šæ‰§è¡Œäº¤æ˜“ç­–ç•¥"""
    cash = 100000
    position = 0
    assets = []

    # è®¡ç®—è¿è¡Œä¸­çš„MA5
    result_df['Run_MA5'] = result_df['Close'].rolling(5).mean().fillna(method='bfill')

    for i in range(len(result_df) - 1):
        price = result_df.iloc[i]['Close']
        pred_next = result_df.iloc[i]['Predicted']
        ma5 = result_df.iloc[i]['Run_MA5']
        dif = result_df.iloc[i]['DIF']
        dea = result_df.iloc[i]['DEA']
        pred_ret = (pred_next - price) / price

        if position == 0:
            cond1 = price > ma5
            cond2 = dif > dea
            cond3 = pred_ret > 0.01
            if cond1 or cond2 or cond3:
                shares = cash // price
                if shares > 0:
                    cash -= shares * price
                    position = shares

        elif position > 0:
            trend_bad = price < ma5
            macd_bad = dif < dea
            ai_panic = pred_ret < -0.015
            if (trend_bad and macd_bad) or ai_panic:
                cash += position * price
                position = 0

        assets.append(cash + position * price)

    assets.append(cash + position * result_df.iloc[-1]['Close'])
    result_df['Asset'] = assets

    final_return = (assets[-1] - 100000) / 100000
    return final_return


# ================= 10. ç»“æœå¯è§†åŒ–ï¼ˆæ›´æ–°ï¼‰ =================
def create_final_report(result_df, r2, test_return, best_score,
                        test_dir_accuracy, valid_dir_accuracy, results_df):
    """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Šå›¾è¡¨ï¼ˆæ›´æ–°ç‰ˆï¼ŒåŒ…å«æ¨¡å‹å¾—åˆ†ï¼‰"""
    fig, axes = plt.subplots(3, 2, figsize=(18, 15))

    # å­å›¾1ï¼šä»·æ ¼é¢„æµ‹
    axes[0, 0].plot(result_df['Date'], result_df['Close'], label='çœŸå®è‚¡ä»·', color='blue', linewidth=2)
    axes[0, 0].plot(result_df['Date'], result_df['Predicted'], label='é¢„æµ‹è‚¡ä»·',
                    color='orange', linestyle='--', alpha=0.8)
    axes[0, 0].set_title(f'æµ‹è¯•é›†é¢„æµ‹å¯¹æ¯” | R2: {r2:.4f}, æ–¹å‘å‡†ç¡®ç‡: {test_dir_accuracy:.1f}%',
                         fontsize=14, fontproperties='SimSun')
    axes[0, 0].legend(prop={'family': 'SimSun'}, loc='upper left')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].set_ylabel('ä»·æ ¼', fontproperties='SimSun')

    # å­å›¾2ï¼šå‚æ•°ç»„åˆæ¨¡å‹å¾—åˆ†åˆ†å¸ƒ
    model_scores = results_df['model_score']
    axes[0, 1].bar(range(len(model_scores)), model_scores,
                   color=['red' if s == max(model_scores) else 'skyblue' for s in model_scores])
    axes[0, 1].axhline(y=model_scores.mean(), color='green', linestyle='--',
                       label=f'å¹³å‡: {model_scores.mean():.1f}')
    axes[0, 1].set_title('10ä¸ªå‚æ•°ç»„åˆçš„æ¨¡å‹ç»¼åˆå¾—åˆ†', fontsize=14, fontproperties='SimSun')
    axes[0, 1].set_xlabel('å‚æ•°ç»„åˆç¼–å·', fontproperties='SimSun')
    axes[0, 1].set_ylabel('æ¨¡å‹ç»¼åˆå¾—åˆ†', fontproperties='SimSun')
    axes[0, 1].legend(prop={'family': 'SimSun'})
    axes[0, 1].grid(True, alpha=0.3)

    # å­å›¾3ï¼šç­–ç•¥å‡€å€¼
    benchmark = result_df['Close'] / result_df['Close'].iloc[0]
    strategy = result_df['Asset'] / 100000

    axes[1, 0].plot(result_df['Date'], benchmark,
                    label=f'åŸºå‡†å‡€å€¼ ({benchmark.iloc[-1] * 100 - 100:.1f}%)', color='gray', alpha=0.7)
    axes[1, 0].plot(result_df['Date'], strategy,
                    label=f'ç­–ç•¥å‡€å€¼ ({test_return * 100:.1f}%)', color='red', linewidth=2.5)
    axes[1, 0].set_title(f'æµ‹è¯•é›†è¡¨ç° | æ”¶ç›Š: {test_return * 100:.2f}% (æ¨¡å‹å¾—åˆ†: {best_score:.1f})',
                         fontsize=14, fontproperties='SimSun')
    axes[1, 0].legend(prop={'family': 'SimSun'}, loc='upper left')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_ylabel('å‡€å€¼', fontproperties='SimSun')

    # å­å›¾4ï¼šæ¨¡å‹å¾—åˆ† vs æ–¹å‘å‡†ç¡®ç‡æ•£ç‚¹å›¾
    scores = results_df['model_score']
    dir_acc = results_df['valid_direction_accuracy']
    colors = ['red' if i == 0 else 'blue' for i in range(len(scores))]
    axes[1, 1].scatter(dir_acc, scores, c=colors, s=100, alpha=0.7)
    axes[1, 1].axhline(y=scores.mean(), color='gray', linestyle='--', alpha=0.5)
    axes[1, 1].axvline(x=dir_acc.mean(), color='gray', linestyle='--', alpha=0.5)

    # æ ‡è®°æœ€ä½³ç»„åˆ
    best_idx = scores.idxmax()
    axes[1, 1].scatter(dir_acc[best_idx], scores[best_idx], c='green', s=200, marker='*',
                       label=f'æœ€ä½³ç»„åˆ {best_idx + 1}')

    axes[1, 1].set_title('éªŒè¯é›†: æ¨¡å‹å¾—åˆ† vs æ–¹å‘å‡†ç¡®ç‡', fontsize=14, fontproperties='SimSun')
    axes[1, 1].set_xlabel('æ–¹å‘å‡†ç¡®ç‡ (%)', fontproperties='SimSun')
    axes[1, 1].set_ylabel('æ¨¡å‹ç»¼åˆå¾—åˆ†', fontproperties='SimSun')
    axes[1, 1].legend(prop={'family': 'SimSun'})
    axes[1, 1].grid(True, alpha=0.3)

    # å­å›¾5ï¼šå›æ’¤åˆ†æ
    asset_series = pd.Series(result_df['Asset'].values)
    cumulative_max = asset_series.cummax()
    drawdown = (asset_series - cumulative_max) / cumulative_max * 100
    axes[2, 0].fill_between(result_df['Date'], drawdown, 0, color='red', alpha=0.3)
    axes[2, 0].axhline(y=0, color='black', linewidth=0.5)
    axes[2, 0].axhline(y=-10, color='orange', linestyle='--', alpha=0.5)
    axes[2, 0].axhline(y=-20, color='red', linestyle='--', alpha=0.5)
    max_dd = drawdown.min()
    axes[2, 0].set_title(f'å›æ’¤åˆ†æ | æœ€å¤§å›æ’¤: {max_dd:.1f}%', fontsize=14, fontproperties='SimSun')
    axes[2, 0].grid(True, alpha=0.3)
    axes[2, 0].set_xlabel('æ—¥æœŸ', fontproperties='SimSun')
    axes[2, 0].set_ylabel('å›æ’¤ (%)', fontproperties='SimSun')

    # å­å›¾6ï¼šæ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
    metrics = ['æ¨¡å‹ç»¼åˆå¾—åˆ†', 'éªŒè¯æ–¹å‘å‡†ç¡®ç‡', 'éªŒè¯R2', 'éªŒè¯RMSE']
    metric_values = [
        best_score,
        valid_dir_accuracy,
        results_df.iloc[best_idx]['valid_r2'] * 100,  # R2è½¬æ¢ä¸ºç™¾åˆ†æ¯”æ˜¾ç¤º
        results_df.iloc[best_idx]['valid_rmse']
    ]
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']

    bars = axes[2, 1].bar(metrics, metric_values, color=colors)
    axes[2, 1].set_title('æœ€ä½³æ¨¡å‹æ€§èƒ½æŒ‡æ ‡', fontsize=14, fontproperties='SimSun')
    axes[2, 1].set_ylabel('å¾—åˆ†/ç™¾åˆ†æ¯”', fontproperties='SimSun')
    axes[2, 1].grid(True, alpha=0.3, axis='y')

    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value, metric in zip(bars, metric_values, metrics):
        height = bar.get_height()
        if metric == 'æ¨¡å‹ç»¼åˆå¾—åˆ†':
            label = f'{value:.1f}'
        elif metric == 'éªŒè¯æ–¹å‘å‡†ç¡®ç‡':
            label = f'{value:.1f}%'
        elif metric == 'éªŒè¯R2':
            label = f'{value:.1f}%'
        else:  # éªŒè¯RMSE
            label = f'{value:.2f}'
        axes[2, 1].text(bar.get_x() + bar.get_width() / 2., height + 1,
                        label, ha='center', va='bottom', fontproperties='SimSun')

    plt.tight_layout()
    plt.savefig('Top10_Parameter_Report.png', dpi=150, bbox_inches='tight')
    plt.show()


# ================= 11. ä¸»å‡½æ•° =================
def main():
    # è®¾ç½®å…¨å±€éšæœºç§å­
    set_random_seeds(SEED)

    print("=" * 60)
    print("ç²¾é€‰LSTMæ¨¡å‹è®­ç»ƒä¸éªŒè¯ç³»ç»Ÿ")
    print(f"éšæœºç§å­: {SEED} (ç¡®ä¿ç»“æœå¯é‡å¤)")
    print("æ•°æ®åˆ’åˆ†: é¢„è®­ç»ƒé›† | éªŒè¯é›† | æµ‹è¯•é›†")
    print(f"å‚æ•°æœç´¢: 10ä¸ªç²¾é€‰ç»„åˆ")
    print("æ¨¡å‹é€‰æ‹©: åŸºäºR2ã€RMSEå’Œæ–¹å‘å‡†ç¡®ç‡çš„ç»¼åˆå¾—åˆ†")
    print("æƒé‡åˆ†é…: R2(30%), RMSE(30%), æ–¹å‘å‡†ç¡®ç‡(40%)")
    print("=" * 60)

    model, result_df, test_return, results_df = train_with_validation()

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Šï¼ˆæ›´æ–°ç‰ˆï¼ŒåŒ…å«æ¨¡å‹å¾—åˆ†ï¼‰
    summary = f"""
    {'=' * 60}
                ç²¾é€‰å‚æ•°ç»„åˆéªŒè¯æŠ¥å‘Šï¼ˆåŸºäºç»¼åˆå¾—åˆ†ï¼‰
    {'=' * 60}
    æ•°æ®åˆ’åˆ†:
    - é¢„è®­ç»ƒé›†: æˆªæ­¢ {PRE_TRAIN_END}
    - éªŒè¯é›†: {VALID_START} è‡³ {VALID_END}
    - æµ‹è¯•é›†: {TEST_START} èµ·

    å‚æ•°æœç´¢:
    - ç²¾é€‰10ä¸ªå‚æ•°ç»„åˆï¼Œè¦†ç›–ä¸åŒé…ç½®
    - åŒ…å«å°å‹ã€ä¸­å‹ã€å¤§å‹ç½‘ç»œ
    - Dropoutç‡: 0.2-0.4
    - å­¦ä¹ ç‡: 0.001, 0.0005

    æ¨¡å‹é€‰æ‹©æ ‡å‡†:
    - ç»¼åˆå¾—åˆ† = R2Ã—30% + RMSEå¾—åˆ†Ã—30% + æ–¹å‘å‡†ç¡®ç‡Ã—40%
    - R2: è¶Šå¤§è¶Šå¥½ï¼Œå½’ä¸€åŒ–åˆ°[0,1]
    - RMSE: è¶Šå°è¶Šå¥½ï¼Œä½¿ç”¨æŒ‡æ•°è¡°å‡è½¬æ¢ä¸ºå¾—åˆ†
    - æ–¹å‘å‡†ç¡®ç‡: è¶Šå¤§è¶Šå¥½ï¼Œå½’ä¸€åŒ–åˆ°[0,1]

    æœ€ä½³ç»„åˆç»“æœ:
    - æ¨¡å‹ç»¼åˆå¾—åˆ†: {results_df.iloc[0]['model_score']:.2f}
    - éªŒè¯é›†R2: {results_df.iloc[0]['valid_r2']:.4f}
    - éªŒè¯é›†RMSE: {results_df.iloc[0]['valid_rmse']:.2f}
    - éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {results_df.iloc[0]['valid_direction_accuracy']:.2f}%
    - éªŒè¯é›†æ”¶ç›Šç‡: {results_df.iloc[0]['valid_return'] * 100:.2f}%
    - æµ‹è¯•é›†æ”¶ç›Šç‡: {test_return * 100:.2f}%
    - æµ‹è¯•é›†æ–¹å‘å‡†ç¡®ç‡: {results_df.iloc[0]['test_direction_accuracy']:.2f}%
    - æµ‹è¯•é›†R2: {results_df.iloc[0]['test_r2']:.4f}
    - æµ‹è¯•é›†RMSE: {results_df.iloc[0]['test_rmse']:.2f}

    å¾—åˆ†åˆ†æ:
    - å¹³å‡æ¨¡å‹ç»¼åˆå¾—åˆ†: {results_df['model_score'].mean():.2f}
    - æœ€é«˜æ¨¡å‹ç»¼åˆå¾—åˆ†: {results_df['model_score'].max():.2f}
    - å¹³å‡éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {results_df['valid_direction_accuracy'].mean():.2f}%
    - æœ€é«˜éªŒè¯é›†æ–¹å‘å‡†ç¡®ç‡: {results_df['valid_direction_accuracy'].max():.2f}%

    è¾“å‡ºæ–‡ä»¶:
    1. top10_parameter_results.csv - 10ä¸ªç»„åˆè¯¦ç»†ç»“æœï¼ˆå«ç»¼åˆå¾—åˆ†ï¼‰
    2. best_model_top10_comboX_scoreX.keras - æœ€ä½³æ¨¡å‹
    3. best_model_params_top10.json - æœ€ä½³æ¨¡å‹å‚æ•°
    4. Top10_Parameter_Report.png - ç»¼åˆæŠ¥å‘Šå›¾è¡¨ï¼ˆå«å¾—åˆ†åˆ†æï¼‰

    ä½¿ç”¨å»ºè®®:
    1. æ¨¡å‹ç»¼åˆå¾—åˆ†è¶Šé«˜è¡¨ç¤ºé¢„æµ‹æ€§èƒ½è¶Šå¥½
    2. å¦‚æœæµ‹è¯•é›†è¡¨ç°ä¸ä½³ï¼Œå¯å°è¯•è°ƒæ•´æƒé‡åˆ†é…
    3. æŸ¥çœ‹top10_parameter_results.csvé€‰æ‹©å…¶ä»–æœ‰æ½œåŠ›çš„ç»„åˆ
    4. å¯ä¿®æ”¹SEEDè¿›è¡Œå¤šæ¬¡å®éªŒéªŒè¯ç¨³å®šæ€§
    5. æ–¹å‘å‡†ç¡®ç‡ > 55% é€šå¸¸è¢«è®¤ä¸ºæ˜¯æœ‰é¢„æµ‹èƒ½åŠ›çš„æ¨¡å‹
    {'=' * 60}
    """

    print(summary)

    with open('Top10_Validation_Summary.txt', 'w', encoding='utf-8') as f:
        f.write(summary)


if __name__ == '__main__':
    main()