import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from collections import Counter
import warnings
from sklearn.metrics import precision_recall_fscore_support

# å¿½ç•¥ pandas çš„ SettingWithCopyWarning
warnings.filterwarnings("ignore")

# --- 1. é…ç½®å‚æ•° ---
# å‡è®¾åŸå§‹æ–‡ä»¶åä¸º '00700(1).txt'
INPUT_FILE_NAME = "00700(1).txt"
CLEANED_CSV_NAME = "00700_preliminary_cleaned.csv"
TRAIN_END_DATE = '2023-12-31'
INVEST_START_DATE = '2024-01-01'
CLASSIFICATION_THRESHOLD = 0.005  # æ¶¨è·Œé˜ˆå€¼ delta = 0.5% (ç”¨äºå®šä¹‰æ ‡ç­¾ Y)

# ä¸­æ–‡åˆ°è‹±æ–‡çš„åˆ—åæ˜ å°„å­—å…¸
COLUMN_MAPPING = {
    'æ—¥æœŸ': 'Date', 'å¼€ç›˜': 'Open', 'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 
    'æ”¶ç›˜': 'Close', 'æˆäº¤é‡': 'Volume', 'æˆäº¤é¢': 'Amount'
}
encodings_to_try = ['gbk', 'gb18030', 'utf-8'] # è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜

# --- 2. æ–‡ä»¶è¯»å–å’Œæ ¼å¼è½¬æ¢ (ç»“åˆä¹‹å‰çš„æ­¥éª¤) ---

def load_and_preprocess_raw_data(file_name):
    """è¯»å–åŸå§‹ TXT æ–‡ä»¶ï¼Œè§£å†³ç¼–ç é—®é¢˜ï¼Œå¹¶è½¬æ¢æ ¼å¼ã€‚"""
    df = None
    print(f"å°è¯•è¯»å–æ–‡ä»¶ï¼š{file_name}")
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(
                file_name, sep='\t', header=0, skiprows=[0], encoding=encoding
            )
            print(f"  - æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–ã€‚")
            break
        except UnicodeDecodeError:
            continue
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ '{file_name}'ã€‚")
            return None

    if df is None:
        print("âŒ è½¬æ¢å¤±è´¥ï¼šæ‰€æœ‰å°è¯•çš„ç¼–ç éƒ½æ— æ³•æ­£ç¡®è§£ææ–‡ä»¶ã€‚")
        return None

    # æ¸…ç†åˆ—åå’Œé‡å‘½å
    original_cols = {col: col.strip() for col in df.columns}
    df.rename(columns=original_cols, inplace=True)
    df.rename(columns=COLUMN_MAPPING, inplace=True)
    
    # åŸºç¡€ç±»å‹è½¬æ¢å’Œæ¸…æ´—
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    price_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Amount']
    df[price_cols] = df[price_cols].apply(pd.to_numeric, errors='coerce')
    df.dropna(how='all', inplace=True) # åˆ é™¤å…¨ç©ºè¡Œ

    print(f"æ•°æ®å·²è½¬æ¢ä¸º {CLEANED_CSV_NAME}")
    # ä¿å­˜ä¸ºä¸­é—´æ–‡ä»¶ï¼Œæ–¹ä¾¿åç»­è°ƒè¯•
    df.to_csv(CLEANED_CSV_NAME, encoding='utf-8')
    return df

# --- 3. å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹å‡½æ•° ---

def feature_engineering(df):
    """è®¡ç®—æ‰€æœ‰ç‰¹å¾æŒ‡æ ‡ (X) å’Œæ„å»ºæ ‡ç­¾ (Y)ã€‚"""
    
    # ==================================================
    # 1ï¸âƒ£ æ”¶ç›Šæ„ŸçŸ¥æ ‡ç­¾ï¼ˆæ›¿æ¢åŸ Next_Day_Return é€»è¾‘ï¼‰
    # ==================================================
    FUTURE_WINDOW = 5          # æœªæ¥ 5 æ—¥
    UP_THRESHOLD = 0.03        # +3%
    DOWN_THRESHOLD = -0.03    # -3%

    df['Future_Close'] = df['Close'].shift(-FUTURE_WINDOW)
    df['Future_Return'] = (df['Future_Close'] / df['Close']) - 1

    df['Target'] = 0
    df.loc[df['Future_Return'] > UP_THRESHOLD, 'Target'] = 1
    df.loc[df['Future_Return'] < DOWN_THRESHOLD, 'Target'] = -1

    print(
        f"\næ”¶ç›Šæ„ŸçŸ¥æ ‡ç­¾ Target æ„å»ºå®Œæˆ "
        f"(æœªæ¥{FUTURE_WINDOW}æ—¥, Â±{UP_THRESHOLD:.0%})ï¼Œ"
        f"æ ‡ç­¾åˆ†å¸ƒï¼š{Counter(df['Target'].dropna())}"
    )

    
    # 2. è®¡ç®—æ—¥æ”¶ç›Šç‡å’ŒåŸºç¡€æ³¢åŠ¨ç‡æŒ‡æ ‡ (ç”¨äºåç»­å› å­è®¡ç®—)
    df['Daily_Return'] = df['Close'].pct_change() 
    df['True_Range'] = df['High'] - df['Low']
    
    # --- B. åŠ¨é‡/è¶‹åŠ¿å› å­ (SMA, EMA, MACD) ---
    SHORT_WINDOW = 12
    LONG_WINDOW = 26
    SIGNAL_WINDOW = 9

    df[f'SMA_{SHORT_WINDOW}'] = df['Close'].rolling(window=SHORT_WINDOW).mean()
    df[f'EMA_{SHORT_WINDOW}'] = df['Close'].ewm(span=SHORT_WINDOW, adjust=False).mean()
    df[f'EMA_{LONG_WINDOW}'] = df['Close'].ewm(span=LONG_WINDOW, adjust=False).mean()

    # MACD
    EMA_Short = df[f'EMA_{SHORT_WINDOW}']
    EMA_Long = df[f'EMA_{LONG_WINDOW}']
    df['MACD_DIF'] = EMA_Short - EMA_Long
    df['MACD_DEA'] = df['MACD_DIF'].ewm(span=SIGNAL_WINDOW, adjust=False).mean()
    df['MACD_HIST'] = df['MACD_DIF'] - df['MACD_DEA']

    # --- C. è¶…ä¹°è¶…å–å› å­ (RSI) ---
    RSI_WINDOW = 14
    delta = df['Close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.ewm(com=RSI_WINDOW - 1, min_periods=RSI_WINDOW).mean()
    avg_loss = loss.ewm(com=RSI_WINDOW - 1, min_periods=RSI_WINDOW).mean()
    RS = avg_gain / avg_loss
    df['RSI'] = 100 - (100 / (1 + RS))
    
    # --- D. æ³¢åŠ¨ç‡å› å­ (Bollinger Bands & ATR) ---
    BB_WINDOW = 20
    BB_DEV = 2
    ATR_WINDOW = 14

    # å¸ƒæ—å¸¦å®½åº¦
    df['BB_Middle'] = df['Close'].rolling(window=BB_WINDOW).mean()
    df['StdDev'] = df['Close'].rolling(window=BB_WINDOW).std()
    df['BB_Upper'] = df['BB_Middle'] + (BB_DEV * df['StdDev'])
    df['BB_Lower'] = df['BB_Middle'] - (BB_DEV * df['StdDev'])
    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle'] 

    # ATR
    df['High_PrevClose'] = abs(df['High'] - df['Close'].shift(1))
    df['Low_PrevClose'] = abs(df['Low'] - df['Close'].shift(1))
    df['TR'] = df[['True_Range', 'High_PrevClose', 'Low_PrevClose']].max(axis=1) # çœŸå®æ³¢å¹… (TR)
    df['ATR'] = df['TR'].rolling(window=ATR_WINDOW).mean() 

    # --- E. é‡ä»·å› å­ä¸æ»åç‰¹å¾ ---
    LAG_N = 5 
    
    # é‡æ¯”
    df['Volume_SMA_5'] = df['Volume'].rolling(window=5).mean()
    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA_5']

    # æ»åç‰¹å¾
    for i in range(1, LAG_N + 1):
        df[f'Return_Lag_{i}'] = df['Daily_Return'].shift(i)

    # --- F. è¡¥å……é«˜é˜¶å› å­ ---
    STAT_WINDOW = 30 # ç”¨äºç»Ÿè®¡è®¡ç®—çš„çª—å£æœŸ

    # 1. ç´¯ç§¯/æ´¾å‘çº¿ (A/D Line)
    mfm = ( (df['Close'] - df['Low']) - (df['High'] - df['Close']) ) / (df['High'] - df['Low']).replace(0, 1e-6)
    mfv = mfm * df['Volume']
    df['AD_Line'] = mfv.cumsum()

    # 2. èƒ½é‡æ½® (OBV)
    obv_series = pd.Series(0, index=df.index)
    obv_series[df['Close'] > df['Close'].shift(1)] = df['Volume']
    obv_series[df['Close'] < df['Close'].shift(1)] = -df['Volume']
    df['OBV'] = obv_series.cumsum()
    
    # 3. Kçº¿å®ä½“æ¯” (Body Ratio) å’Œå½±çº¿æ¯”
    df['Body_Length'] = abs(df['Close'] - df['Open'])
    df['Body_Ratio'] = (df['Body_Length'] / df['True_Range']).replace(np.inf, 1).fillna(0) 
    df['Upper_Wick'] = df['High'] - df[['Open', 'Close']].max(axis=1)
    df['Upper_Wick_Ratio'] = (df['Upper_Wick'] / df['True_Range']).replace(np.inf, 1).fillna(0)

    # 4. æ”¶ç›˜ä»·ä¸ä¸­è½¨ (MA) çš„æ ‡å‡†åŒ–åå·®
    df['Close_vs_MA_Dev'] = (df['Close'] - df['BB_Middle']) / df['Close'] 

    # 5. æ”¶ç›Šç‡çš„æ»šåŠ¨ç»Ÿè®¡é‡
    df['Return_Skew'] = df['Daily_Return'].rolling(window=STAT_WINDOW).skew()
    df['Return_Kurt'] = df['Daily_Return'].rolling(window=STAT_WINDOW).kurt()

    # --- G. æœ€ç»ˆæ¸…ç†ä¸åˆ’åˆ† ---
    df.dropna(inplace=True)

    # å®šä¹‰ç‰¹å¾å’Œæ ‡ç­¾åˆ—
    EXCLUDED_COLS = [
        'Future_Close',
        'Future_Return',
        'Next_Day_Close',
        'Next_Day_Return',
        'Target',
        'TR',
        'High_PrevClose',
        'Low_PrevClose',
        'Body_Length',
        'Upper_Wick',
        'Volume_SMA_5',
        'StdDev'
    ]

    EXCLUDED_COLS = [
        'Next_Day_Close', 'Next_Day_Return',
        'Future_Close', 'Future_Return',   # â† æ–°å¢
        'Target', 'TR', 'High_PrevClose', 'Low_PrevClose',
        'Body_Length', 'Upper_Wick', 'Volume_SMA_5', 'StdDev'
    ]

    X = df[FEATURE_COLUMNS]
    Y = df[LABEL_COLUMN]

    # ä¸¥æ ¼åˆ’åˆ†è®­ç»ƒé›†å’ŒæŠ•èµ„é›†
    X_train = X.loc[X.index <= TRAIN_END_DATE]
    Y_train = Y.loc[Y.index <= TRAIN_END_DATE]
    X_test = X.loc[X.index >= INVEST_START_DATE]

    print("-" * 50)
    print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼")
    print(f"æœ€ç»ˆç‰¹å¾æ•°é‡ (X): {len(FEATURE_COLUMNS)} ä¸ª")
    print(f"è®­ç»ƒé›†å¤§å° (X_train/Y_train): {len(X_train)} ä¸ªæ ·æœ¬ (æ—¥æœŸèŒƒå›´: {X_train.index.min()} - {X_train.index.max()})")
    print(f"æŠ•èµ„é›†å¤§å° (X_test): {len(X_test)} ä¸ªæ ·æœ¬")
    print("-" * 50)
    return X_train, Y_train, X_test, FEATURE_COLUMNS


# --- 4. å› å­è¯„åˆ¤å‡½æ•° (ä½¿ç”¨ LightGBM) ---

def evaluate_features_with_lgbm(X_train, Y_train, feature_names):
    """
    ä½¿ç”¨ LightGBM åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶æå–ç‰¹å¾é‡è¦æ€§ã€‚
    """
    print("ğŸ“¢ å¼€å§‹è¿›è¡Œå› å­é‡è¦æ€§è¯„åˆ¤ (åŸºäº LightGBM)...")
    
    # å¯¹ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ– (æ¨èæ“ä½œï¼Œå¯¹æ ‘æ¨¡å‹ä¸æ˜¯å¿…é¡»ï¼Œä½†å¯¹åç»­æ¨¡å‹èåˆæœ‰ç›Š)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # å®šä¹‰ LightGBM å‚æ•°
    # objective='multiclass': å› ä¸ºæ˜¯ä¸‰åˆ†ç±»é—®é¢˜ (1, 0, -1)
    lgb_params = {
        'objective': 'multiclass',
        'metric': 'multi_logloss',
        'num_class': 3,
        'boosting_type': 'gbdt',
        'n_estimators': 500, # è¿­ä»£æ¬¡æ•°
        'learning_rate': 0.05,
        'feature_fraction': 0.8, # éšæœºé€‰æ‹©ç‰¹å¾æ¯”ä¾‹ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
        'bagging_fraction': 0.8,
        'bagging_freq': 1,
        'verbose': -1, # å…³é—­è¾“å‡º
        'n_jobs': -1,
        'seed': 42
    }
    
    # è®­ç»ƒæ¨¡å‹
    model = lgb.LGBMClassifier(**lgb_params)
    model.fit(X_train_scaled, Y_train)
    
    # æå–ç‰¹å¾é‡è¦æ€§
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    print("-" * 50)
    print("ğŸ“Š å› å­é‡è¦æ€§è¯„ä¼°ç»“æœ (Top 15):")
    print(importance_df.head(15).to_markdown(index=False))
    print("-" * 50)
    
    # è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆå¯é€‰ï¼‰
    cv_scores = cross_val_score(model, X_train_scaled, Y_train, cv=5, scoring='f1_macro', n_jobs=-1)
    print(f"æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„ F1-Macro 5æŠ˜äº¤å‰éªŒè¯å¹³å‡å¾—åˆ†: {cv_scores.mean():.4f}")
    
    y_pred = model.predict(X_train_scaled)
    p, r, f, _ = precision_recall_fscore_support(Y_train, y_pred, average='macro')

    print(f"Precision (Macro): {p:.4f}")
    print(f"Recall (Macro): {r:.4f}")
    print(f"F1-Score (Macro): {f:.4f}")
    return importance_df


# --- 5. ä¸»ç¨‹åºè¿è¡Œ ---

if __name__ == "__main__":
    # 1. è¯»å–å’Œé¢„å¤„ç†åŸå§‹æ–‡ä»¶
    df_full = load_and_preprocess_raw_data(INPUT_FILE_NAME)
    
    if df_full is not None:
        # 2. ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é›†åˆ’åˆ†
        X_train, Y_train, X_test, feature_names = feature_engineering(df_full.copy())
        
        # 3. å› å­è¯„åˆ¤
        if len(X_train) > 0:
            importance_df = evaluate_features_with_lgbm(X_train, Y_train, feature_names)
        else:
            print("âš ï¸ è®­ç»ƒé›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå› å­è¯„åˆ¤ã€‚è¯·æ£€æŸ¥æ•°æ®æ—¥æœŸå’Œçª—å£æœŸè®¾ç½®ã€‚")